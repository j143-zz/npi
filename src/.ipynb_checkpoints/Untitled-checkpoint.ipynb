{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_lstm = mx.rnn.SequentialRNNCell()\n",
    "for i in range(2):\n",
    "    f_lstm.add(mx.rnn.LSTMCell(num_hidden=256, prefix='lstm_l%d_'%i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "bucket_size = 60\n",
    "NUM_OF_ROWS = 4\n",
    "NUM_OF_COLUMNS = 9\n",
    "ONE_HOT_DEPTH = 10\n",
    "MAX_ARGS_NUM = 3\n",
    "ARG_DEPTH = 10\n",
    "MAX_PROG_NUM = 10\n",
    "PROG_VEC_SIZE = 16\n",
    "KEY_VEC_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_env = mx.sym.Variable('curr_env')\n",
    "curr_prog = mx.sym.Variable('curr_prog')\n",
    "curr_args = mx.sym.Variable('curr_args')\n",
    "next_end = mx.sym.Variable('next_end')\n",
    "next_prog = mx.sym.Variable('next_prog')\n",
    "next_args = mx.sym.Variable('next_args')\n",
    "\n",
    "prog_memory = mx.sym.arange(start=0, stop=MAX_PROG_NUM, name='prog_memory')\n",
    "\n",
    "curr_env_reshaped = mx.sym.Reshape(curr_env, shape=(batch_size * bucket_size, -1))\n",
    "curr_args_reshaped = mx.sym.Reshape(curr_args, shape=(batch_size * bucket_size, -1))\n",
    "env_args_concat = mx.sym.Concat(curr_env_reshaped, curr_args_reshaped, dim=1, name='s_t')\n",
    "\n",
    "        #f_enc\n",
    "f_enc_fc1 = mx.sym.FullyConnected(data=env_args_concat, num_hidden=256, name='f_enc_fc1')\n",
    "f_enc_act1 = mx.sym.Activation(data=f_enc_fc1, act_type='relu', name='f_enc_act1')\n",
    "f_enc = mx.sym.FullyConnected(data=f_enc_act1, num_hidden=128, name='f_enc')\n",
    "        # (batch_size * bucket_size, 128)\n",
    "\n",
    "        #program embedding\n",
    "prog_embedding = mx.sym.Embedding(data=curr_prog, input_dim=MAX_PROG_NUM,\n",
    "                                           output_dim=PROG_VEC_SIZE, name='prog_embedding')\n",
    "key_memory = mx.sym.FullyConnected(data=prog_memory, num_hidden=KEY_VEC_SIZE, name='key_memory')\n",
    "prog_embedding_reshaped = mx.sym.Reshape(prog_embedding, shape=(batch_size * bucket_size, -1))\n",
    "curr_inputs = mx.sym.Concat(f_enc, prog_embedding_reshaped, dim=1, name='curr_inputs')\n",
    "\n",
    "        # 2-layer MLP with ReLU activation and linear decoder\n",
    "curr_inputs_fc1 = mx.sym.FullyConnected(data=curr_inputs, num_hidden=128, name='curr_inputs_fc1')\n",
    "curr_inputs_act1 = mx.sym.Activation(data=curr_inputs_fc1, act_type='relu', name='curr_inputs_act1')\n",
    "enc_inputs = mx.sym.FullyConnected(data=curr_inputs_act1, num_hidden=32, name='enc_inputs')\n",
    "enc_inputs_reshaped = mx.sym.Reshape(enc_inputs, shape=(batch_size, bucket_size, -1))\n",
    "\n",
    "        # 2-layer lstm core\n",
    "f_lstm.reset()\n",
    "outputs, states = f_lstm.unroll(bucket_size, inputs=enc_inputs_reshaped, merge_outputs=True)\n",
    "\n",
    "outputs_reshaped = mx.sym.Reshape(outputs, shape=(-1, 256))\n",
    "\n",
    "        # f_end\n",
    "f_end_fc1 = mx.sym.FullyConnected(data=outputs_reshaped, num_hidden=2, name='f_end_fc1')\n",
    "next_end_reshaped = mx.sym.Reshape(next_end, shape=(-1,))\n",
    "f_end = mx.sym.SoftmaxOutput(data=f_end_fc1, label=next_end_reshaped, name='f_end')\n",
    "\n",
    "        # f_prog\n",
    "f_prog_fc1 = mx.sym.FullyConnected(data=outputs_reshaped, num_hidden=KEY_VEC_SIZE, name='f_prog_fc1')\n",
    "f_prog_dot = mx.sym.dot(f_prog_fc1, key_memory, transpose_b=True, name='f_prog_dot')\n",
    "\n",
    "        #f_prog_choice = mx.sym.argmax(data=f_prog_dot, axis=1, name='f_prog_choice')\n",
    "next_prog_reshaped = mx.sym.Reshape(next_prog, shape=(-1,))\n",
    "f_prog = mx.sym.SoftmaxOutput(data=f_prog_dot, label=next_prog_reshaped, name='f_prog')\n",
    "\n",
    "# f_args\n",
    "next_args_reshaped = mx.sym.Reshape(next_args, shape=(-1, MAX_ARGS_NUM, ARG_DEPTH), name='next_args_reshaped')\n",
    "next_args_numeric = mx.sym.argmax(data=next_args_reshaped, axis=2, name='next_args_numeric')\n",
    "args = mx.sym.SliceChannel(next_args_numeric, axis=1, num_outputs=3)\n",
    "f_arg0_fc1 = mx.sym.FullyConnected(data=outputs_reshaped, num_hidden=ARG_DEPTH, name='f_arg0_fc1')\n",
    "f_arg1_fc1 = mx.sym.FullyConnected(data=outputs_reshaped, num_hidden=ARG_DEPTH, name='f_arg1_fc1')\n",
    "f_arg2_fc1 = mx.sym.FullyConnected(data=outputs_reshaped, num_hidden=ARG_DEPTH, name='f_arg2_fc1')\n",
    "arg0_label = mx.sym.Reshape(args[0], shape=(-1,))\n",
    "arg1_label = mx.sym.Reshape(args[1], shape=(-1,))\n",
    "arg2_label = mx.sym.Reshape(args[2], shape=(-1,))\n",
    "f_arg0_softmax = mx.sym.SoftmaxOutput(data=f_arg0_fc1, label=arg0_label, name='f_arg0_softmax')\n",
    "f_arg1_softmax = mx.sym.SoftmaxOutput(data=f_arg1_fc1, label=arg2_label, name='f_arg1_softmax')\n",
    "f_arg2_softmax = mx.sym.SoftmaxOutput(data=f_arg2_fc1, label=arg2_label, name='f_arg2_softmax')\n",
    "f_args_concat = mx.sym.Concat(f_arg0_softmax, f_arg1_softmax, f_arg2_softmax, dim=1, name='f_args_concat')\n",
    "f_args = mx.sym.Reshape(f_args_concat, shape=(batch_size, bucket_size, MAX_ARGS_NUM, ARG_DEPTH))\n",
    "out = mx.sym.Group([f_end, f_prog, f_args])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx.viz.plot_network(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
